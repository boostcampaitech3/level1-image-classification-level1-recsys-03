{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "UmDju1hmS-__",
      "metadata": {
        "id": "UmDju1hmS-__"
      },
      "source": [
        "## Lesson 5 - Model\n",
        " - 이번 실습 자료에서는 강의시간에 다루었던 파이토치 모델을 정의하는 방법에 대해 실습하겠습니다.\n",
        " - 파이토치 모델은 기본적으로 `nn.Module` 클래스를 상속하여 사용합니다.\n",
        "     - [공식문서](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)에 따르면 `nn.Module` 은 다음과 같은 기능을 합니다\n",
        "     ```\n",
        "     Base class for all neural network modules.\n",
        "     Your models should also subclass this class.\n",
        "     Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes:\n",
        "     ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "zCROkRzlS-_7",
      "metadata": {
        "id": "zCROkRzlS-_7"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "toANDtC5S_AA",
      "metadata": {
        "id": "toANDtC5S_AA"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3, bias=True)\n",
        "        self.bn1 = nn.BatchNorm2d(num_features=3)\n",
        "        self.conv2 = nn.Conv2d(in_channels=3, out_channels=5, kernel_size=3, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        return F.relu(self.conv2(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "uWxGW2iyS_AB",
      "metadata": {
        "id": "uWxGW2iyS_AB"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Model(\n",
              "  (conv1): Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv2): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              ")"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = Model()\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NtmySw1gS_AC",
      "metadata": {
        "id": "NtmySw1gS_AC"
      },
      "source": [
        "### 모델 디버깅\n",
        " - 파이토치 모델들은 다음과 같읕 방법들을 통해 파라미터를 눈으로 확인할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "sX8A26RhS_AD",
      "metadata": {
        "id": "sX8A26RhS_AD",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "conv1.weight         - size: torch.Size([3, 1, 3, 3])\n",
            "Parameter containing:\n",
            "tensor([[[[-0.2500, -0.1243, -0.2524],\n",
            "          [-0.0348,  0.2156, -0.2962],\n",
            "          [-0.0547,  0.0366, -0.3217]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2274,  0.1173,  0.2428],\n",
            "          [ 0.3236, -0.0628, -0.0311],\n",
            "          [ 0.1467, -0.1174,  0.2254]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2126,  0.2160, -0.0055],\n",
            "          [ 0.0955, -0.1705,  0.2118],\n",
            "          [ 0.1571, -0.1833,  0.2524]]]], requires_grad=True)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "conv1.bias           - size: torch.Size([3])\n",
            "Parameter containing:\n",
            "tensor([-0.3020, -0.0305,  0.3019], requires_grad=True)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "bn1.weight           - size: torch.Size([3])\n",
            "Parameter containing:\n",
            "tensor([1., 1., 1.], requires_grad=True)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "bn1.bias             - size: torch.Size([3])\n",
            "Parameter containing:\n",
            "tensor([0., 0., 0.], requires_grad=True)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "conv2.weight         - size: torch.Size([5, 3, 3, 3])\n",
            "Parameter containing:\n",
            "tensor([[[[ 0.0881, -0.0941,  0.1165],\n",
            "          [-0.1630,  0.1712, -0.1903],\n",
            "          [-0.0285, -0.0536, -0.1448]],\n",
            "\n",
            "         [[ 0.0385,  0.0893, -0.0349],\n",
            "          [ 0.1076,  0.0646,  0.1338],\n",
            "          [-0.1465,  0.0582, -0.1783]],\n",
            "\n",
            "         [[ 0.1758,  0.0214, -0.0903],\n",
            "          [ 0.1851, -0.0924, -0.1704],\n",
            "          [ 0.1392,  0.0278, -0.0403]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1795,  0.1656,  0.1347],\n",
            "          [ 0.0905,  0.0109, -0.0372],\n",
            "          [ 0.1774,  0.0644,  0.0774]],\n",
            "\n",
            "         [[-0.1134,  0.1081, -0.0493],\n",
            "          [ 0.1387,  0.0467, -0.1356],\n",
            "          [ 0.1296, -0.0021, -0.1743]],\n",
            "\n",
            "         [[ 0.1786, -0.1221, -0.1765],\n",
            "          [-0.0942, -0.0024,  0.1532],\n",
            "          [-0.0077, -0.1064,  0.0171]]],\n",
            "\n",
            "\n",
            "        [[[-0.1056,  0.0389,  0.1076],\n",
            "          [ 0.0871, -0.1801,  0.0756],\n",
            "          [ 0.0843, -0.1536,  0.0347]],\n",
            "\n",
            "         [[-0.0684, -0.1193, -0.1723],\n",
            "          [ 0.0906, -0.0194, -0.0792],\n",
            "          [ 0.0893, -0.0116, -0.1122]],\n",
            "\n",
            "         [[-0.0783,  0.1754,  0.1355],\n",
            "          [-0.0694, -0.0694,  0.1687],\n",
            "          [-0.1497, -0.0880,  0.1909]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0530,  0.0494, -0.1603],\n",
            "          [ 0.0941,  0.1783, -0.1763],\n",
            "          [ 0.0527, -0.1578,  0.0634]],\n",
            "\n",
            "         [[-0.0770,  0.0068, -0.0112],\n",
            "          [ 0.1273, -0.1258, -0.0993],\n",
            "          [-0.1891, -0.1203,  0.1693]],\n",
            "\n",
            "         [[-0.1460,  0.0261,  0.0377],\n",
            "          [-0.1243, -0.0238,  0.1315],\n",
            "          [ 0.1738, -0.1576,  0.0993]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1625,  0.1386, -0.1597],\n",
            "          [-0.1614, -0.1912,  0.1406],\n",
            "          [ 0.1005, -0.0091,  0.0035]],\n",
            "\n",
            "         [[ 0.1897,  0.0995,  0.1143],\n",
            "          [ 0.1851, -0.0273, -0.1705],\n",
            "          [ 0.0508, -0.0772, -0.1831]],\n",
            "\n",
            "         [[-0.1246,  0.1798,  0.0690],\n",
            "          [-0.1238, -0.1502,  0.0701],\n",
            "          [-0.1335, -0.1771,  0.1454]]]], requires_grad=True)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 1. named_parameters() 를 이용하는 방식\n",
        "for param, weight in model.named_parameters():\n",
        "    print(f\"{param:20} - size: {weight.size()}\")\n",
        "    print(weight)\n",
        "    print(\"-\" * 100)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "RGOd8u6NS_AD",
      "metadata": {
        "id": "RGOd8u6NS_AD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[[[-0.2500, -0.1243, -0.2524],\n",
            "          [-0.0348,  0.2156, -0.2962],\n",
            "          [-0.0547,  0.0366, -0.3217]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2274,  0.1173,  0.2428],\n",
            "          [ 0.3236, -0.0628, -0.0311],\n",
            "          [ 0.1467, -0.1174,  0.2254]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2126,  0.2160, -0.0055],\n",
            "          [ 0.0955, -0.1705,  0.2118],\n",
            "          [ 0.1571, -0.1833,  0.2524]]]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.3020, -0.0305,  0.3019], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "# 2. 멤버 변수를 이용하여 직접 access 하는 방법\n",
        "print(model.conv1.weight)\n",
        "print(model.conv1.bias)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PV5CYMXRS_AE",
      "metadata": {
        "id": "PV5CYMXRS_AE"
      },
      "source": [
        "### 학습된 모델 저장하기\n",
        " - `torch.save(model.state_dict(), save_path)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "Cq8GYbN1S_AF",
      "metadata": {
        "id": "Cq8GYbN1S_AF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "./runs/best.pth 폴더에 모델이 성공적으로 저장되었습니다.\n",
            "해당 폴더의 파일 리스트: ['best.pth']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "save_folder = \"./runs/\"\n",
        "save_path = os.path.join(save_folder, \"best.pth\")   # ./runs/best.pth\n",
        "os.makedirs(save_folder, exist_ok=True)  \n",
        "\n",
        "torch.save(model.state_dict(), save_path)\n",
        "print(f\"{save_path} 폴더에 모델이 성공적으로 저장되었습니다.\")\n",
        "print(f\"해당 폴더의 파일 리스트: {os.listdir(save_folder)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BqwVdTsKS_AF",
      "metadata": {
        "id": "BqwVdTsKS_AF"
      },
      "source": [
        "### 저장된 모델 불러오기\n",
        " - model.load_state_dict(torch.load(save_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "bZ4UN19tS_AG",
      "metadata": {
        "id": "bZ4UN19tS_AG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "./runs/best.pth 에서 성공적으로 모델을 load 하였습니다.\n"
          ]
        }
      ],
      "source": [
        "new_model = Model()\n",
        "new_model.load_state_dict(torch.load(save_path))\n",
        "print(f\"{save_path} 에서 성공적으로 모델을 load 하였습니다.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WZn5x9SdS_AG",
      "metadata": {
        "id": "WZn5x9SdS_AG"
      },
      "source": [
        "#### 저장된 모델이 잘 불러와졌는지 확인해봅시다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "qRYRythjS_AH",
      "metadata": {
        "id": "qRYRythjS_AH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "파라미터 conv1.weight    에 대하여 trained 모델과 load 된 모델의 값이 같나요? -> True\n",
            "파라미터 conv1.bias      에 대하여 trained 모델과 load 된 모델의 값이 같나요? -> True\n",
            "파라미터 bn1.weight      에 대하여 trained 모델과 load 된 모델의 값이 같나요? -> True\n",
            "파라미터 bn1.bias        에 대하여 trained 모델과 load 된 모델의 값이 같나요? -> True\n",
            "파라미터 conv2.weight    에 대하여 trained 모델과 load 된 모델의 값이 같나요? -> True\n"
          ]
        }
      ],
      "source": [
        "for (name, trained_weight), (_, saved_weight) in zip(model.named_parameters(), new_model.named_parameters()):\n",
        "    is_equal = torch.equal(trained_weight, saved_weight)\n",
        "    print(f\"파라미터 {name:15} 에 대하여 trained 모델과 load 된 모델의 값이 같나요? -> {is_equal}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "z9JD_kYqS_AH",
      "metadata": {
        "id": "z9JD_kYqS_AH"
      },
      "source": [
        "#### state_dict() 이 무엇인가요?\n",
        " - 모델의 저장과 로딩에 `state_dict()` 을 사용하는데, 기능이 무엇인가요?\n",
        " - 기본적으로 위에서 살펴본 `.named_parameters()` 와 매우 유사합니다\n",
        " - model parameter 를 Key 로 가지고, model weights 를 Value 로 가지는 파이썬 딕셔너리일 뿐입니다. \n",
        "   (정확한 Type 은 파이썬 내장 라이브러리 collections.OrderDict 입니다)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "0yKFEBJTS_AH",
      "metadata": {
        "id": "0yKFEBJTS_AH",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "파라미터 네임 conv1.weight              / 사이즈: torch.Size([3, 1, 3, 3])\n",
            "tensor([[[[-0.2500, -0.1243, -0.2524],\n",
            "          [-0.0348,  0.2156, -0.2962],\n",
            "          [-0.0547,  0.0366, -0.3217]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2274,  0.1173,  0.2428],\n",
            "          [ 0.3236, -0.0628, -0.0311],\n",
            "          [ 0.1467, -0.1174,  0.2254]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2126,  0.2160, -0.0055],\n",
            "          [ 0.0955, -0.1705,  0.2118],\n",
            "          [ 0.1571, -0.1833,  0.2524]]]])\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "파라미터 네임 conv1.bias                / 사이즈: torch.Size([3])\n",
            "tensor([-0.3020, -0.0305,  0.3019])\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "파라미터 네임 bn1.weight                / 사이즈: torch.Size([3])\n",
            "tensor([1., 1., 1.])\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "파라미터 네임 bn1.bias                  / 사이즈: torch.Size([3])\n",
            "tensor([0., 0., 0.])\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "파라미터 네임 bn1.running_mean          / 사이즈: torch.Size([3])\n",
            "tensor([0., 0., 0.])\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "파라미터 네임 bn1.running_var           / 사이즈: torch.Size([3])\n",
            "tensor([1., 1., 1.])\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "파라미터 네임 bn1.num_batches_tracked   / 사이즈: torch.Size([])\n",
            "tensor(0)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "파라미터 네임 conv2.weight              / 사이즈: torch.Size([5, 3, 3, 3])\n",
            "tensor([[[[ 0.0881, -0.0941,  0.1165],\n",
            "          [-0.1630,  0.1712, -0.1903],\n",
            "          [-0.0285, -0.0536, -0.1448]],\n",
            "\n",
            "         [[ 0.0385,  0.0893, -0.0349],\n",
            "          [ 0.1076,  0.0646,  0.1338],\n",
            "          [-0.1465,  0.0582, -0.1783]],\n",
            "\n",
            "         [[ 0.1758,  0.0214, -0.0903],\n",
            "          [ 0.1851, -0.0924, -0.1704],\n",
            "          [ 0.1392,  0.0278, -0.0403]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1795,  0.1656,  0.1347],\n",
            "          [ 0.0905,  0.0109, -0.0372],\n",
            "          [ 0.1774,  0.0644,  0.0774]],\n",
            "\n",
            "         [[-0.1134,  0.1081, -0.0493],\n",
            "          [ 0.1387,  0.0467, -0.1356],\n",
            "          [ 0.1296, -0.0021, -0.1743]],\n",
            "\n",
            "         [[ 0.1786, -0.1221, -0.1765],\n",
            "          [-0.0942, -0.0024,  0.1532],\n",
            "          [-0.0077, -0.1064,  0.0171]]],\n",
            "\n",
            "\n",
            "        [[[-0.1056,  0.0389,  0.1076],\n",
            "          [ 0.0871, -0.1801,  0.0756],\n",
            "          [ 0.0843, -0.1536,  0.0347]],\n",
            "\n",
            "         [[-0.0684, -0.1193, -0.1723],\n",
            "          [ 0.0906, -0.0194, -0.0792],\n",
            "          [ 0.0893, -0.0116, -0.1122]],\n",
            "\n",
            "         [[-0.0783,  0.1754,  0.1355],\n",
            "          [-0.0694, -0.0694,  0.1687],\n",
            "          [-0.1497, -0.0880,  0.1909]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0530,  0.0494, -0.1603],\n",
            "          [ 0.0941,  0.1783, -0.1763],\n",
            "          [ 0.0527, -0.1578,  0.0634]],\n",
            "\n",
            "         [[-0.0770,  0.0068, -0.0112],\n",
            "          [ 0.1273, -0.1258, -0.0993],\n",
            "          [-0.1891, -0.1203,  0.1693]],\n",
            "\n",
            "         [[-0.1460,  0.0261,  0.0377],\n",
            "          [-0.1243, -0.0238,  0.1315],\n",
            "          [ 0.1738, -0.1576,  0.0993]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1625,  0.1386, -0.1597],\n",
            "          [-0.1614, -0.1912,  0.1406],\n",
            "          [ 0.1005, -0.0091,  0.0035]],\n",
            "\n",
            "         [[ 0.1897,  0.0995,  0.1143],\n",
            "          [ 0.1851, -0.0273, -0.1705],\n",
            "          [ 0.0508, -0.0772, -0.1831]],\n",
            "\n",
            "         [[-0.1246,  0.1798,  0.0690],\n",
            "          [-0.1238, -0.1502,  0.0701],\n",
            "          [-0.1335, -0.1771,  0.1454]]]])\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for param, weight in model.state_dict().items():\n",
        "    print(f\"파라미터 네임 {param:25} / 사이즈: {weight.size()}\")\n",
        "    print(weight)\n",
        "    print(\"-\" * 100, end=\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "Ed5j0w3rS_AI",
      "metadata": {
        "id": "Ed5j0w3rS_AI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model.state_dict() 의 Type : <class 'collections.OrderedDict'>\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from collections import OrderedDict\n",
        "print(f\"model.state_dict() 의 Type : {type(model.state_dict())}\")\n",
        "isinstance(model.state_dict(), OrderedDict)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aoJVB7XUS_AI",
      "metadata": {
        "id": "aoJVB7XUS_AI"
      },
      "source": [
        "#### `named_parameters()` 을 안쓰고 `state_dict()` 을 사용하는 이유가 무언인가요? (둘이 뭐가 다른가요)\n",
        " - `named_parameters()` : returns only parameters\n",
        " - `state_dict()`: returns both parameters and buffers (e.g. BN runnin_mean, running_var)\n",
        " \n",
        " [Reference](https://stackoverflow.com/a/54747245)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "rKBfbJJYS_AJ",
      "metadata": {
        "id": "rKBfbJJYS_AJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['conv1.weight', 'conv1.bias', 'bn1.weight', 'bn1.bias', 'conv2.weight']\n",
            "\n",
            "['conv1.weight',\n",
            " 'conv1.bias',\n",
            " 'bn1.weight',\n",
            " 'bn1.bias',\n",
            " 'bn1.running_mean',\n",
            " 'bn1.running_var',\n",
            " 'bn1.num_batches_tracked',\n",
            " 'conv2.weight']\n"
          ]
        }
      ],
      "source": [
        "pprint([name for (name, param) in model.named_parameters()])  # named_parameters() : returns only parameters\n",
        "print()\n",
        "pprint(list(model.state_dict().keys()))                       # state_dict(): retuns both parameters and buffers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vZBCDWBfS_AJ",
      "metadata": {
        "id": "vZBCDWBfS_AJ"
      },
      "source": [
        "### CPU vs GPU\n",
        " - Pytorch 텐서(데이터)는 다양한 프로세서(CPU, GPU, TPU) 에서 연산 및 학습이 가능합니다.\n",
        " - 따라서, 특정 프로세서에서 학습을 진행하고 싶은 경우 해당 프로세스를 명시적으로 지정해주어야 합니다.\n",
        " - 이는 해당 텐서(데이터)를 특정 프로세스의 메모리에 load 또는 해당 프로세스의 메모리로 이동하는 것을 의미합니다.\n",
        " - 따라서, 연산하는 텐서들의 디바이스가 같아야만 연산이 가능합니다. 그렇지 않을 경우 에러가 발생합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mmCL_sXES_AK",
      "metadata": {
        "id": "mmCL_sXES_AK"
      },
      "source": [
        "#### 새로운 텐서 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "I_EH9jgOS_AK",
      "metadata": {
        "id": "I_EH9jgOS_AK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "데이터 디바이스: cpu\n",
            "데이터 디바이스: cuda:0\n",
            "데이터 디바이스: cpu\n"
          ]
        }
      ],
      "source": [
        "data = torch.randn(2,2, device=torch.device('cpu'))     # CPU 에 새로운 텐서 생성\n",
        "print(f\"데이터 디바이스: {data.device}\")\n",
        "\n",
        "data = torch.randn(2,2, device=torch.device('cuda:0'))  # GPU 0번에 새로운 텐서 생성\n",
        "print(f\"데이터 디바이스: {data.device}\")\n",
        "\n",
        "data = torch.randn(2,2)                                 # device 를 따로 지정하지 않으면 default 로 CPU 에 생성됩니다.\n",
        "print(f\"데이터 디바이스: {data.device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FcA2NEVmS_AK",
      "metadata": {
        "id": "FcA2NEVmS_AK"
      },
      "source": [
        "#### 이미 생성되어 있는 텐서를 다른 프로세스의 메모리로 이동하는 것도 가능합니다\n",
        "#### .cpu()\n",
        "모든 모델의 파라미터와 버터를 CPU 메모리로 이동"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "c8R3ygRRS_AL",
      "metadata": {
        "id": "c8R3ygRRS_AL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "파라미터 디바이스: cpu\n",
            "파라미터 디바이스: cpu\n",
            "파라미터 디바이스: cpu\n",
            "파라미터 디바이스: cpu\n",
            "파라미터 디바이스: cpu\n"
          ]
        }
      ],
      "source": [
        "model.cpu()\n",
        "for weight in model.parameters():\n",
        "    print(f\"파라미터 디바이스: {weight.device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GobjlWa6S_AL",
      "metadata": {
        "id": "GobjlWa6S_AL"
      },
      "source": [
        "#### .cuda()\n",
        "모든 모델의 파라미터와 버터를 GPU 메모리로 이동"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "Knj_icpAS_AL",
      "metadata": {
        "id": "Knj_icpAS_AL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "파라미터 디바이스: cuda:0\n",
            "파라미터 디바이스: cuda:0\n",
            "파라미터 디바이스: cuda:0\n",
            "파라미터 디바이스: cuda:0\n",
            "파라미터 디바이스: cuda:0\n"
          ]
        }
      ],
      "source": [
        "model.cuda()\n",
        "for weight in model.parameters():\n",
        "    print(f\"파라미터 디바이스: {weight.device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qwOb6ccTS_AM",
      "metadata": {
        "id": "qwOb6ccTS_AM"
      },
      "source": [
        "#### .to()\n",
        "파라미터 또는 버퍼 메모리를 다음 프로세스로 이동"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "pEOar6EWS_AM",
      "metadata": {
        "id": "pEOar6EWS_AM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "파라미터 디바이스를 cpu 로 변경\n",
            "파라미터 디바이스: cpu\n",
            "파라미터 디바이스: cpu\n",
            "파라미터 디바이스: cpu\n",
            "파라미터 디바이스: cpu\n",
            "파라미터 디바이스: cpu\n",
            "\n",
            "파라미터 디바이스를 cuda 로 변경\n",
            "파라미터 디바이스: cuda:0\n",
            "파라미터 디바이스: cuda:0\n",
            "파라미터 디바이스: cuda:0\n",
            "파라미터 디바이스: cuda:0\n",
            "파라미터 디바이스: cuda:0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "device_options = ['cpu', 'cuda']\n",
        "for device_option in device_options:\n",
        "    device = torch.device(device_option)\n",
        "    model.to(device)\n",
        "    \n",
        "    print(f\"파라미터 디바이스를 {device_option} 로 변경\")\n",
        "    for weight in model.parameters():\n",
        "        print(f\"파라미터 디바이스: {weight.device}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "l1ve5Ky2S_AN",
      "metadata": {
        "id": "l1ve5Ky2S_AN"
      },
      "source": [
        "#### Cautions\n",
        "\n",
        "새로운 텐서를 GPU 에 생성하고 싶은 경우 `torch.randn(2,2).cuda()` 처럼 생성하면\n",
        "\n",
        "1) CPU 메모리에 텐서를 생성 2) CPU -> GPU 메모리로 값을 이동하는 과정이 일어나면서 cost efficient 하지 못합니다\n",
        "\n",
        "`torch.randn(2,2, device=torch.device('cuda:0'))` 와 같이 처음부터 GPU 메모리에 생성하는 것을 권장합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bq7KXuyfS_AN",
      "metadata": {
        "id": "bq7KXuyfS_AN"
      },
      "source": [
        "#### Cautions\n",
        " - 연산하는 두 개의 텐서는 반드시 같은 device 에 존재하여야 합니다.\n",
        " - 그렇지 않으면 에러가 발생합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "2LjfibL_S_AN",
      "metadata": {
        "id": "2LjfibL_S_AN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-0.1846, -0.3361],\n",
            "        [ 3.0285,  1.1365]])\n"
          ]
        }
      ],
      "source": [
        "data1 = torch.randn(2,2, device=torch.device('cpu'))\n",
        "data2 = torch.randn(2,2, device=torch.device('cpu'))\n",
        "print(data1 + data2)  # 두 텐서가 같은 device(CPU) 에 있기에 연산이 가능합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "KpDpGzCqS_AO",
      "metadata": {
        "id": "KpDpGzCqS_AO"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-243f39335071>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 두 텐서가 다른 device(CPU, GPU) 에 있기에 연산이 불가능합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
          ]
        }
      ],
      "source": [
        "data1 = torch.randn(2,2, device=torch.device('cpu'))\n",
        "data2 = torch.randn(2,2, device=torch.device('cuda'))\n",
        "print(data1 + data2)  # 두 텐서가 다른 device(CPU, GPU) 에 있기에 연산이 불가능합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wcvHa8G5S_AO",
      "metadata": {
        "id": "wcvHa8G5S_AO"
      },
      "source": [
        "### forward\n",
        " - nn.Module 을 상속한 객체를 직접 호출할 때 수행하는 연산을 정의합니다.\n",
        " - `model(input)` 을 통해 모델의 예측값을 계산할 수 있습니다.\n",
        " - Defines the computation performed at every call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UXQuTb-4S_AO",
      "metadata": {
        "id": "UXQuTb-4S_AO",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "dummy_input = torch.randn(1, 1, 12, 12, device=device)\n",
        "model.to(device)\n",
        "output = model(dummy_input)\n",
        "print(f\"모델 output 사이즈: {output.size()}\")\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IrbF9fD9S_AP",
      "metadata": {
        "id": "IrbF9fD9S_AP"
      },
      "source": [
        "#### Cautions\n",
        " - 위에서 말씀드린 것과 같은 원리로 모델과 인풋의 device 는 반드시 같아야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "o-pjTeVaS_AP",
      "metadata": {
        "id": "o-pjTeVaS_AP"
      },
      "outputs": [],
      "source": [
        "cpu_device = torch.device('cpu')\n",
        "gpu_device = torch.device('cuda')\n",
        "\n",
        "# device is same\n",
        "dummy_input = dummy_input.to(gpu_device)\n",
        "model.to(gpu_device)\n",
        "output = model(dummy_input)  # 잘 작동합니다 \n",
        "print(f\"모델 ouput 사이즈: {output.size()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aAwqrvnpS_AP",
      "metadata": {
        "id": "aAwqrvnpS_AP",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "dummy_input = dummy_input.to(cpu_device)\n",
        "model.to(gpu_device)\n",
        "\n",
        "# device is different\n",
        "# RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same\n",
        "output = model(dummy_input)  # 에러 발생\n",
        "print(f\"모델 ouput 사이즈: {output.size()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "P8ThIO4jS_AQ",
      "metadata": {
        "id": "P8ThIO4jS_AQ"
      },
      "source": [
        "### requires_grad()\n",
        " - autograd 가 해당 모델의 연산을 기록할지를 결정합니다\n",
        " - false 일 시, 수행하는 연산을 기록하지 않고 따라서 역전파가 되지 않아 학습에서 제외됩니다.\n",
        " - Change if autograd should record operations on parameters in this module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ixAWEZ3iS_AQ",
      "metadata": {
        "id": "ixAWEZ3iS_AQ"
      },
      "outputs": [],
      "source": [
        "# requires_grad = False\n",
        "model.requires_grad_(requires_grad=False)\n",
        "for param, weight in model.named_parameters():\n",
        "    print(f\"파라미터 {param:15} 가 gradient 를 tracking 하나요? -> {weight.requires_grad}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rysdVfBOS_AR",
      "metadata": {
        "id": "rysdVfBOS_AR"
      },
      "outputs": [],
      "source": [
        "# requires_grad = True\n",
        "model.requires_grad_(requires_grad=True)\n",
        "for param, weight in model.named_parameters():\n",
        "    print(f\"파라미터 {param:15} 가 gradient 를 tracking 하나요? -> {weight.requires_grad}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4oj9DI74S_AR",
      "metadata": {
        "id": "4oj9DI74S_AR"
      },
      "source": [
        "### train(), eval()\n",
        " - 모델을 training(evaluation) 모드로 전환합니다.\n",
        " - training 과 evaluation 이 다르게 작용하는 모듈들(Dropout, BatchNorm) 에 영향을 줍니다.\n",
        " - 학습 단계에서는 training 모드로, 인퍼런스 단계에서는 eval 모드로 전환해주어야 합니다.\n",
        " - [아래](https://github.com/pytorch/pytorch/blob/1.6/torch/nn/modules/batchnorm.py#L110-L117)는 BatchNorm2d 의 파이토치 구현입니다. `self.training=True` 일 경우에만, `running_mean`, `running_var` 을 tracking 합니다.\n",
        " \n",
        "```\n",
        "if self.training and self.track_running_stats:\n",
        "    # TODO: if statement only here to tell the jit to skip emitting this when it is None\n",
        "    if self.num_batches_tracked is not None:\n",
        "        self.num_batches_tracked = self.num_batches_tracked + 1\n",
        "        if self.momentum is None:  # use cumulative moving average\n",
        "            exponential_average_factor = 1.0 / float(self.num_batches_tracked)\n",
        "        else:  # use exponential moving average\n",
        "            exponential_average_factor = self.momentum\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tCxiUYFmS_AS",
      "metadata": {
        "id": "tCxiUYFmS_AS"
      },
      "outputs": [],
      "source": [
        "model.train()  # train mode 로 전환\n",
        "print(f\"model.bn1.training: {model.bn1.training}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NoQ2axpcS_AS",
      "metadata": {
        "id": "NoQ2axpcS_AS"
      },
      "outputs": [],
      "source": [
        "model.eval()  # eval mode 로 전환\n",
        "print(f\"model.bn1.training: {model.bn1.training}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Jvvl6abnS_AS",
      "metadata": {
        "id": "Jvvl6abnS_AS"
      },
      "source": [
        "### 파이토치 공식 문서에서 nn.Module 에 관한 더 많은 정보를 얻을 수 있습니다.\n",
        "https://pytorch.org/docs/stable/generated/torch.nn.Module.html\n",
        "\n",
        "궁금증이 생기면 공식 문서를 참고하는걸 강력 추천합니다."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "5_Model (정답).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
