{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, num_classes, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=7, stride=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.25)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(-1, 128)\n",
    "        return self.fc(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Custom Model Template\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, num_classes, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        1. 위와 같이 생성자의 parameter 에 num_claases 를 포함해주세요.\n",
    "        2. 나만의 모델 아키텍쳐를 디자인 해봅니다.\n",
    "        3. 모델의 output_dimension 은 num_classes 로 설정해주세요.\n",
    "        \"\"\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        1. 위에서 정의한 모델 아키텍쳐를 forward propagation 을 진행해주세요\n",
    "        2. 결과로 나온 output 을 return 해주세요\n",
    "        \"\"\"\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ResNetModel(nn.Module):\n",
    "    def __init__(self, num_classes, **kwargs):\n",
    "        super().__init__()\n",
    "        self._num_classes = num_classes\n",
    "        self.resnet18 = torchvision.models.resnet18(pretrained=True, num_classes=1000)\n",
    "        self._haircut(self.num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.resnet18(x)\n",
    "    \n",
    "    def _haircut(self, num_classes):\n",
    "        self.resnet18.fc = torch.nn.Linear(in_features = 512, out_features = num_classes, bias = True)\n",
    "        torch.nn.init.xavier_uniform_(self.resnet18.fc.weight)\n",
    "        stdv = 1. / (self.resnet18.fc.weight.size(1)) ** 0.5\n",
    "        self.resnet18.fc.bias.data.uniform_(-stdv, stdv)\n",
    "    \n",
    "    @property\n",
    "    def num_classes(self):\n",
    "        return self._num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vgg19Model(nn.Module):\n",
    "    def __init__(self, num_classes, **kwargs):\n",
    "        super().__init__()\n",
    "        self._num_classes = num_classes\n",
    "        self.vgg19 = torchvision.models.vgg19(pretrained=True)\n",
    "        self._haircut(self.num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.vgg19(x)\n",
    "    \n",
    "    def _haircut(self, num_classes):\n",
    "        self.vgg19.classifier[-1] = torch.nn.Linear(in_features = 4096, out_features = num_classes, bias = True)\n",
    "        torch.nn.init.xavier_uniform_(self.vgg19.classifier[-1].weight)\n",
    "        stdv = 1. / (self.vgg19.classifier[-1].weight.size(1)) ** 0.5\n",
    "        self.vgg19.classifier[-1].bias.data.uniform_(-stdv, stdv)\n",
    "    \n",
    "    @property\n",
    "    def num_classes(self):\n",
    "        return self._num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coatnet import CoAtNet\n",
    "from torchvision.transforms import Resize, CenterCrop, Compose, ToPILImage, ToTensor\n",
    "\n",
    "class CoAtNetModel(nn.Module):\n",
    "    IMAGE_SIZE = (512, 384)\n",
    "    AFTER_TRANS = (224, 224)\n",
    "    \n",
    "    def __init__(self, num_classes, **kwargs):\n",
    "        super().__init__()\n",
    "        self._num_classes = num_classes\n",
    "        \n",
    "        num_blocks = [2, 2, 3, 5, 2]    \n",
    "        channels = [64, 96, 192, 384, 768] \n",
    "        self.coatnet = CoAtNet(self.AFTER_TRANS, 3, num_blocks, channels, num_classes=self._num_classes)\n",
    "        \n",
    "        self.trfm = Compose([\n",
    "            ToPILImage(),\n",
    "            Resize(min(self.AFTER_TRANS)),\n",
    "            CenterCrop(size=self.AFTER_TRANS),\n",
    "            ToTensor()\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        x = x.cpu()\n",
    "        x_ = [self.trfm(img) for img in x]\n",
    "        x = torch.stack(x_, dim=0)\n",
    "        x = x.to(device)\n",
    "        return self.coatnet(x)\n",
    "    \n",
    "    @property\n",
    "    def num_classes(self):\n",
    "        return self._num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import MaskBaseDataset\n",
    "\n",
    "class MergeLabel(nn.Module):\n",
    "    def __init__(self, num_classes, saved_dir, **kwargs):\n",
    "        super(MergeLabel, self).__init__()\n",
    "        self.age_model = ResNetModel(3)\n",
    "        self.gender_model = ResNetModel(2)\n",
    "        self.mask_model = ResNetModel(3)\n",
    "        \n",
    "        age_dir=f'{saved_dir}/age/best.pth'\n",
    "        gender_dir=f'{saved_dir}/gender/best.pth'\n",
    "        mask_dir=f'{saved_dir}/mask/best.pth'\n",
    "        \n",
    "        self.age_model.load_state_dict(torch.load(age_dir))\n",
    "        self.gender_model.load_state_dict(torch.load(gender_dir))\n",
    "        self.mask_model.load_state_dict(torch.load(mask_dir))\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, x):\n",
    "        N = x.shape[0]\n",
    "        dtype = x.dtype\n",
    "        device = x.device\n",
    "        \n",
    "        age = self.age_model(x)\n",
    "        gender = self.gender_model(x)\n",
    "        mask = self.mask_model(x)\n",
    "        \n",
    "        for label in [age, gender, mask]:\n",
    "            label.to(device)\n",
    "        \n",
    "        # x = [MaskBaseDataset.encode_multi_class(mask[i], gender[i], age[i]) for i in range(x.shape[0])]\n",
    "        x = torch.zeros(N)\n",
    "        x = x.to(device).type(dtype)\n",
    "        for i in range(N):\n",
    "            one_hot_encoding = mask[i].argmax(), gender[i].argmax(), age[i].argmax()\n",
    "            x[i] = MaskBaseDataset.encode_multi_class(*one_hot_encoding)\n",
    "        \n",
    "        x = F.one_hot(x.long(), num_classes=18)\n",
    "        return x.float()#.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 384, 512])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataset import MaskBaseDataset\n",
    "from dataset import CustomAugmentation\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    base = BaseModel(18)\n",
    "    \n",
    "    age = ResNetModel(3)\n",
    "    gender = ResNetModel(2)\n",
    "    mask = ResNetModel(3)\n",
    "    \n",
    "    # total = MergeLabel(None, \"/opt/ml/workspace/baseline/model\")\n",
    "    \n",
    "    vgg = Vgg19Model(18)\n",
    "    coatnet = CoAtNetModel(18)\n",
    "\n",
    "    dataset = MaskBaseDataset('/opt/ml/input/data/train/images')\n",
    "    dataset.set_transform(CustomAugmentation((384, 512), mean=1.0, std=1.0))\n",
    "\n",
    "    x = dataset[0][0]\n",
    "x.shape\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 18])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coatnet = CoAtNetModel(18)\n",
    "coatnet(x.unsqueeze(0)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9183673469387754"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "768/196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
