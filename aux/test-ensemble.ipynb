{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python inference.py --model PretrainedModels --model_param resnet false --output_filename output-ResNet50_kfold_Ep60_Weightv0_AGM-20220302-ijkimmmy.csv --label age gender mask --model_dir ./model/age/ResNet50_Ep60_Weightv0_AGE ./model/gender/ResNet50_Ep60_Weightv0_GENDER ./model/mask/ResNet50_Ep60_Weightv0_MASK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/ml/bc-ai-recsys3-lv1-imgclassification\n"
     ]
    }
   ],
   "source": [
    "# !pwd\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "model_dirs = ['./model/age/ResNet50_Ep60_Weightv0_AGE']\n",
    "\n",
    "# # no need for other args (besides output_filename & container env)\n",
    "# configs = []\n",
    "# for model_dir in model_dirs:\n",
    "#     with open(os.path.join(model_dir, 'config.json'), 'r') as jsonfile:\n",
    "#         config = json.load(jsonfile)\n",
    "#         config['model_dir'] = model_dir\n",
    "#         configs.append(config)\n",
    "def parse_config(model_dirs):\n",
    "    # reads config files for models\n",
    "    import json\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    label_numclasses = {\n",
    "        'age': 3,\n",
    "        'gender': 2,\n",
    "        'mask': 3\n",
    "    }\n",
    "    \n",
    "    configs = dict((label, []) for label in label_numclasses.keys())\n",
    "    for idx, model_dir in enumerate(model_dirs):\n",
    "        with open(os.path.join(model_dir, 'config.json'), 'r') as jsonfile:\n",
    "            config = json.load(jsonfile)\n",
    "            label = config['label']\n",
    "            config['num_classes'] = label_numclasses[label]\n",
    "            config['model_dir'] = model_dir\n",
    "            configs[label].append(config)\n",
    "    return configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from importlib import import_module\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import model.model as model_model\n",
    "from dataset import TestDataset, MaskBaseDataset\n",
    "from model.loss import create_criterion\n",
    "\n",
    "#  'model': 'PretrainedModels',\n",
    "#  'model_param': ['resnet', 'false'],\n",
    "#  'label': 'age',\n",
    "#  'model_dir': './model/age/ResNet50_Ep60_Weightv0_AGE'}\n",
    "def load_model(model_name, saved_model, num_classes, model_param, device):\n",
    "    model_cls = getattr(model_model, model_name)\n",
    "    model = model_cls(\n",
    "        num_classes=num_classes,\n",
    "        **model_param\n",
    "    )\n",
    "    \n",
    "    model_path = os.path.join(saved_model, 'best.pth')\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device), strict=False)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def set_models(configs):\n",
    "    # takes as input a list of configurations with same labels\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    model_param_module = getattr(import_module(\"train\"), 'parse_model_param')\n",
    "    for config in configs:\n",
    "        pretrained = config['model'] in ['VGGFace', 'PretrainedModels']\n",
    "        model_param = model_param_module(config['model_param'], pretrained)\n",
    "        model = load_model(\n",
    "            config['model'],\n",
    "            config['model_dir'],\n",
    "            config['num_classes'],\n",
    "            model_param,\n",
    "            device\n",
    "        )\n",
    "        model = torch.nn.DataParallel(model)\n",
    "        config['model'] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating inference results for ['./model/age/ResNet50_Ep60_Weightv0_AGE']..\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# def inference_models(models, model_dir:str, loader: DataLoader):\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "df_soft = pd.DataFrame()\n",
    "df_hard = pd.DataFrame()\n",
    "for model in models:\n",
    "    model.eval()\n",
    "    print(f\"Calculating inference results for {model_dirs}..\")\n",
    "    with torch.no_grad():\n",
    "        for idx, images in enumerate(loader):\n",
    "            images = images.to(device)\n",
    "            pred = model(images)\n",
    "            pred_hard = pred.argmax(dim=-1).cpu().numpy()\n",
    "            pred_soft = pred.cpu().numpy()\n",
    "            df_preds = df_preds.append([pred_soft, pred_hard])\n",
    "            # pred = pred.argmax(dim=-1)\n",
    "            # preds.extend(pred.cpu().numpy())\n",
    "    preds_all.append(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seed': 42,\n",
       " 'epochs': 60,\n",
       " 'dataset': 'MaskSplitByProfileDataset',\n",
       " 'augmentation': 'CustomAugmentation',\n",
       " 'resize': [224, 224],\n",
       " 'batch_size': 64,\n",
       " 'valid_batch_size': 200,\n",
       " 'k_folds': 5,\n",
       " 'model_param': ['resnet', 'false'],\n",
       " 'optimizer': 'SGD',\n",
       " 'lr': 0.001,\n",
       " 'val_ratio': 0.2,\n",
       " 'criterion': 'cross_entropy',\n",
       " 'lr_decay_step': 20,\n",
       " 'log_interval': 20,\n",
       " 'name': 'ResNet50_Ep60_Weightv0_AGE',\n",
       " 'label': 'age',\n",
       " 'weight_version': 0,\n",
       " 'data_dir': '/opt/ml/input/data/train/images',\n",
       " 'model_dir': './model/age/ResNet50_Ep60_Weightv0_AGE',\n",
       " 'num_classes': 3,\n",
       " 'model_name': 'PretrainedModels'}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_cf = configs['age'][0]\n",
    "age_cf['model_name'] = age_cf['model']\n",
    "del age_cf['model']\n",
    "age_cf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/ml/bc-ai-recsys3-lv1-imgclassification\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import argparse\n",
    "# import os\n",
    "# from importlib import import_module\n",
    "# import argparse\n",
    "# import os\n",
    "# from importlib import import_module\n",
    "\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import torch\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# import model.model as model_model\n",
    "# from dataset import TestDataset, MaskBaseDataset\n",
    "# from model.loss import create_criterion\n",
    "\n",
    "\n",
    "# def load_model(model_name, saved_model, num_classes, model_param, device):\n",
    "#     model_cls = getattr(model_model, model_name)\n",
    "#     model = model_cls(\n",
    "#         num_classes=num_classes,\n",
    "#         **model_param\n",
    "#     )\n",
    "    \n",
    "#     model_path = os.path.join(saved_model, 'best.pth')\n",
    "#     model.load_state_dict(torch.load(model_path, map_location=device), strict=False)\n",
    "#     return model\n",
    "\n",
    "\n",
    "# def parse_config(model_dirs):\n",
    "#     # parse config files for model directory\n",
    "#     import json\n",
    "#     from collections import defaultdict\n",
    "    \n",
    "#     label_numclasses = {\n",
    "#         'age': 3,\n",
    "#         'gender': 2,\n",
    "#         'mask': 3\n",
    "#     }\n",
    "    \n",
    "#     configs = dict((label, []) for label in label_numclasses.keys())\n",
    "#     for idx, model_dir in enumerate(model_dirs):\n",
    "#         with open(os.path.join(model_dir, 'config.json'), 'r') as jsonfile:\n",
    "#             config = json.load(jsonfile)\n",
    "#             print(config)\n",
    "#             label = config['label']\n",
    "#             config['num_classes'] = label_numclasses[label]\n",
    "#             config['model_dir'] = model_dir\n",
    "#             config['model_name'] = config['model']\n",
    "#             del config['model']\n",
    "#             configs[label].append(config)\n",
    "#     return configs\n",
    "\n",
    "\n",
    "# def set_models(configs):\n",
    "#     # takes as input a list of configurations with same labels, add model within config\n",
    "#     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "#     model_param_module = getattr(import_module(\"train\"), 'parse_model_param')\n",
    "#     for config in configs:\n",
    "#         pretrained = config['model'] in ['VGGFace', 'PretrainedModels']\n",
    "#         model_param = model_param_module(config['model_param'], pretrained)\n",
    "#         model = load_model(\n",
    "#             config['model'],\n",
    "#             config['model_dir'],\n",
    "#             config['num_classes'],\n",
    "#             model_param,\n",
    "#             device\n",
    "#         )\n",
    "#         model = torch.nn.DataParallel(model)\n",
    "#         config['model'] = model\n",
    "\n",
    "\n",
    "# @torch.no_grad()\n",
    "# def inference(data_dir, model_dirs, output_dir, args):\n",
    "#     img_root = os.path.join(data_dir, 'images')\n",
    "#     info_path = os.path.join(data_dir, 'info.csv')\n",
    "#     info = pd.read_csv(info_path)\n",
    "\n",
    "#     img_paths = [os.path.join(img_root, img_id) for img_id in info.ImageID]\n",
    "#     dataset = TestDataset(img_paths, args.resize)\n",
    "#     loader = torch.utils.data.DataLoader(\n",
    "#         dataset,\n",
    "#         batch_size=args.batch_size,\n",
    "#         num_workers=8,\n",
    "#         shuffle=False,\n",
    "#         pin_memory=torch.cuda.is_available(),\n",
    "#         drop_last=False,\n",
    "#     )\n",
    "    \n",
    "#     configs_label = parse_config(model_dirs)\n",
    "#     for _, config in configs_label.items():\n",
    "#         set_models(config)\n",
    "    \n",
    "#     assert all([configs_label['age'], configs_label['gender'], configs_label['mask']]) # must have em all\n",
    "#     age_soft, age_hard = inference_model(configs_label['age'], loader)\n",
    "#     gen_soft, gen_hard = inference_model(configs_label['gender'], loader)\n",
    "#     msk_soft, msk_hard = inference_model(configs_label['mask'], loader)\n",
    "    \n",
    "#     pred_soft = msk_soft*6 + gen_soft * 3 + age_soft\n",
    "#     pred_hard = msk_hard*6 + gen_hard * 3 + age_hard\n",
    "    \n",
    "#     info['ans'] = pred_soft\n",
    "#     info.to_csv(os.path.join(output_dir, 'soft', args.output_filename), index=False)\n",
    "#     info['ans'] = pred_hard\n",
    "#     info.to_csv(os.path.join(output_dir, 'hard', args.output_filename), index=False)\n",
    "#     print(f'Inference Done!')\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "from importlib import import_module\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import model.model as model_model\n",
    "from dataset import TestDataset, MaskBaseDataset\n",
    "from model.loss import create_criterion\n",
    "\n",
    "\n",
    "def load_model(model_name, saved_model, num_classes, model_param, device):\n",
    "    model_cls = getattr(model_model, model_name)\n",
    "    model = model_cls(\n",
    "        num_classes=num_classes,\n",
    "        **model_param\n",
    "    )\n",
    "    \n",
    "    model_path = os.path.join(saved_model, 'best.pth')\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device), strict=False)\n",
    "    return model\n",
    "\n",
    "\n",
    "def parse_config(model_dirs):\n",
    "    # parse config files for model directory\n",
    "    import json\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    label_numclasses = {\n",
    "        'age': 3,\n",
    "        'gender': 2,\n",
    "        'mask': 3\n",
    "    }\n",
    "    \n",
    "    configs = dict((label, []) for label in label_numclasses.keys())\n",
    "    for idx, model_dir in enumerate(model_dirs.split(sep=' ')):\n",
    "    # for idx, model_dir in enumerate(model_dirs):\n",
    "        with open(os.path.join(model_dir, 'config.json'), 'r') as jsonfile:\n",
    "            config = json.load(jsonfile)\n",
    "            label = config['label']\n",
    "            config['num_classes'] = label_numclasses[label]\n",
    "            config['model_dir'] = model_dir\n",
    "            config['model_name'] = config['model']\n",
    "            del config['model']\n",
    "            configs[label].append(config)\n",
    "    return configs\n",
    "\n",
    "\n",
    "def set_models(configs):\n",
    "    # takes as input a list of configurations with same labels, add model within config\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    model_param_module = getattr(import_module(\"train\"), 'parse_model_param')\n",
    "    for config in configs:\n",
    "        pretrained = config['model_name'] in ['VGGFace', 'PretrainedModels']\n",
    "        model_param = model_param_module(config['model_param'], pretrained)\n",
    "        model = load_model(\n",
    "            config['model_name'],\n",
    "            config['model_dir'],\n",
    "            config['num_classes'],\n",
    "            model_param,\n",
    "            device\n",
    "        )\n",
    "        model = torch.nn.DataParallel(model)\n",
    "        config['model'] = model\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def inference(data_dir, model_dirs, output_dir, args):\n",
    "    img_root = os.path.join(data_dir, 'images')\n",
    "    info_path = os.path.join(data_dir, 'info.csv')\n",
    "    info = pd.read_csv(info_path)\n",
    "\n",
    "    img_paths = [os.path.join(img_root, img_id) for img_id in info.ImageID]\n",
    "    dataset = TestDataset(img_paths, args.resize)\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=args.batch_size,\n",
    "        num_workers=8,\n",
    "        shuffle=False,\n",
    "        pin_memory=torch.cuda.is_available(),\n",
    "        drop_last=False,\n",
    "    )\n",
    "    \n",
    "    configs_label = parse_config(model_dirs)\n",
    "    for _, config in configs_label.items():\n",
    "        set_models(config)\n",
    "    \n",
    "    assert all([configs_label['age'], configs_label['gender'], configs_label['mask']]) # must have em all\n",
    "    age_soft, age_hard = inference_model(configs_label['age'], loader)\n",
    "    gen_soft, gen_hard = inference_model(configs_label['gender'], loader)\n",
    "    msk_soft, msk_hard = inference_model(configs_label['mask'], loader)\n",
    "    \n",
    "    pred_soft = msk_soft*6 + gen_soft * 3 + age_soft\n",
    "    pred_hard = msk_hard*6 + gen_hard * 3 + age_hard\n",
    "    \n",
    "    info['ans'] = pred_soft\n",
    "    info.to_csv(os.path.join(output_dir, 'soft', args.output_filename), index=False)\n",
    "    info['ans'] = pred_hard\n",
    "    info.to_csv(os.path.join(output_dir, 'hard', args.output_filename), index=False)\n",
    "    print(f'Inference Done!')\n",
    "\n",
    "\n",
    "def inference_model(configs, loader):\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "    \n",
    "    lst_soft = []\n",
    "    df_hard = pd.DataFrame()\n",
    "    for config in configs:\n",
    "        model = config['model']\n",
    "        model_name = config['model_dir']\n",
    "        model.eval()\n",
    "        \n",
    "        preds = []\n",
    "        print(f\"Calculating inference results for {model_name}..\")\n",
    "        with torch.no_grad():\n",
    "            for idx, images in enumerate(loader):\n",
    "                images = images.to(device)\n",
    "                pred = model(images)\n",
    "                pred = pred.cpu().numpy()\n",
    "                preds.extend(pred)\n",
    "                pred_hard = pred.argmax(axis=-1)\n",
    "                df_hard[model_name] = pred_hard\n",
    "        lst_soft.append(preds)\n",
    "    np_soft = np.array(lst_soft)\n",
    "    np_soft = np_soft.sum(axis=1)/np_soft.shape[1]\n",
    "    np_soft = np_soft.argmax(axis=-1)\n",
    "    np_hard = np.asarray(df_hard.mode(axis=1)[0])\n",
    "\n",
    "    return np_soft, np_hard\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     parser = argparse.ArgumentParser()\n",
    "\n",
    "#     # Data and model checkpoints directories\n",
    "#     parser.add_argument('--batch_size', type=int, default=500, help='input batch size for validing (default: 1000)')\n",
    "#     parser.add_argument('--resize', type=tuple, default=(224, 224), help='resize size for image when you trained (default: (96, 128))')\n",
    "#     parser.add_argument('--output_filename', type=str, default='output.csv')\n",
    "\n",
    "#     # Container environment\n",
    "#     parser.add_argument('--data_dir', type=str, default=os.environ.get('SM_CHANNEL_EVAL', '/opt/ml/input/data/eval'))\n",
    "#     parser.add_argument('--model_dirs', nargs='+', default=os.environ.get('SM_CHANNEL_MODEL', './model'))\n",
    "#     parser.add_argument('--output_dir', type=str, default=os.environ.get('SM_OUTPUT_DATA_DIR', './output'))\n",
    "\n",
    "#     args = parser.parse_args()\n",
    "\n",
    "#     data_dir = args.data_dir\n",
    "#     model_dirs = args.model_dirs\n",
    "#     output_dir = args.output_dir\n",
    "\n",
    "#     os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "#     inference(data_dir, model_dirs, output_dir, args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/opt/ml/input/data/eval'\n",
    "resize = (224, 224)\n",
    "batch_size = 200\n",
    "\n",
    "img_root = os.path.join(data_dir, 'images')\n",
    "info_path = os.path.join(data_dir, 'info.csv')\n",
    "info = pd.read_csv(info_path)\n",
    "\n",
    "img_paths = [os.path.join(img_root, img_id) for img_id in info.ImageID]\n",
    "dataset = TestDataset(img_paths, resize)\n",
    "loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=8,\n",
    "    shuffle=False,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating inference results for ./model/age/ResNet_Ep120_patience15_SplitProf_Downsample_CustAugv1_WeightedCEnSamplev1_SGD_AGE..\n",
      "Calculating inference results for ./model/age/ResNet50_Ep60_Weightv0_AGE..\n",
      "Calculating inference results for ./model/age/ResNet50_Ep60_Weightv3_AGE..\n",
      "Calculating inference results for ./model/age/ResNet_Ep120_patience15_SplitProf_Downsample_CustAugv1_WeightedCEnSamplev1_SGD_AGE..\n",
      "Calculating inference results for ./model/age/ResNet18_Ep60_Weightv3_AGE..\n",
      "Calculating inference results for ./model/age/ResNet50_Ep60_Weightv0_AGE..\n",
      "Calculating inference results for ./model/age/ResNet50_Ep60_Weightv3_AGE..\n",
      "Calculating inference results for ./model/gender/ResNet_Ep120_patience15_SplitProf_Downsample_CustAugv1_WeightedCEnSamplev1_SGD_GENDER..\n",
      "Calculating inference results for ./model/gender/ResNet50_Ep60_Weightv0_GENDER2..\n",
      "Calculating inference results for ./model/gender/ResNet50_Ep60_Weightv3_GENDER..\n",
      "Calculating inference results for ./model/gender/ResNet_Ep120_patience15_SplitProf_Downsample_CustAugv1_WeightedCEnSamplev1_SGD_GENDER..\n",
      "Calculating inference results for ./model/gender/ResNet18_Ep60_Weightv3_GENDER..\n",
      "Calculating inference results for ./model/gender/ResNet50_Ep60_Weightv0_GENDER2..\n",
      "Calculating inference results for ./model/gender/ResNet50_Ep60_Weightv3_GENDER..\n",
      "Calculating inference results for ./model/mask/ResNet_Ep120_patience15_SplitProf_Downsample_CustAugv1_WeightedCEnSamplev1_SGD_MASK..\n",
      "Calculating inference results for ./model/mask/ResNet50_Ep60_Weightv0_MASK2..\n",
      "Calculating inference results for ./model/mask/ResNet50_Ep60_Weightv3_MASK..\n",
      "Calculating inference results for ./model/mask/ResNet_Ep120_patience15_SplitProf_Downsample_CustAugv1_WeightedCEnSamplev1_SGD_MASK..\n",
      "Calculating inference results for ./model/mask/ResNet18_Ep60_Weightv3_MASK..\n",
      "Calculating inference results for ./model/mask/ResNet50_Ep60_Weightv0_MASK2..\n",
      "Calculating inference results for ./model/mask/ResNet50_Ep60_Weightv3_MASK..\n"
     ]
    }
   ],
   "source": [
    "# ./model/age/ResNet_Ep120_patience15_SplitProf_Downsample_CustAugv1_WeightedCEnSamplev1_SGD_AGE ./model/gender/ResNet_Ep120_patience15_SplitProf_Downsample_CustAugv1_WeightedCEnSamplev1_SGD_GENDER ./model/mask/ResNet_Ep120_patience15_SplitProf_Downsample_CustAugv1_WeightedCEnSamplev1_SGD_MASK \\\n",
    "# ./model/age/ResNet50_Ep60_Weightv0_AGE ./model/gender/ResNet50_Ep60_Weightv0_GENDER2 ./model/mask/ResNet50_Ep60_Weightv0_MASK2 \\\n",
    "# ./model/age/ResNet50_Ep60_Weightv3_AGE ./model/gender/ResNet50_Ep60_Weightv3_GENDER ./model/mask/ResNet50_Ep60_Weightv3_MASK ./model/age/ResNet_Ep120_patience15_SplitProf_Downsample_CustAugv1_WeightedCEnSamplev1_SGD_AGE ./model/gender/ResNet_Ep120_patience15_SplitProf_Downsample_CustAugv1_WeightedCEnSamplev1_SGD_GENDER ./model/mask/ResNet_Ep120_patience15_SplitProf_Downsample_CustAugv1_WeightedCEnSamplev1_SGD_MASK \\\\\n",
    "# ./model/age/ResNet18_Ep60_Weightv3_AGE ./model/gender/ResNet18_Ep60_Weightv3_GENDER ./model/mask/ResNet18_Ep60_Weightv3_MAS./model/age/ResNet50_Ep60_Weightv0_AGE ./model/gender/ResNet50_Ep60_Weightv0_GENDER2 ./model/mask/ResNet50_Ep60_Weightv0_MASK2 \\K./model/age/ResNet50_Ep60_Weightv3_AGE ./model/gender/ResNet50_Ep60_Weightv3_GENDER ./model/mask/ResNet50_Ep60_Weightv3_MASK \\\n",
    "\n",
    "model_dirs = \"./model/age/ResNet_Ep120_patience15_SplitProf_Downsample_CustAugv1_WeightedCEnSamplev1_SGD_AGE ./model/gender/ResNet_Ep120_patience15_SplitProf_Downsample_CustAugv1_WeightedCEnSamplev1_SGD_GENDER ./model/mask/ResNet_Ep120_patience15_SplitProf_Downsample_CustAugv1_WeightedCEnSamplev1_SGD_MASK \\\n",
    "./model/age/ResNet50_Ep60_Weightv0_AGE ./model/gender/ResNet50_Ep60_Weightv0_GENDER2 ./model/mask/ResNet50_Ep60_Weightv0_MASK2 \\\n",
    "./model/age/ResNet50_Ep60_Weightv3_AGE ./model/gender/ResNet50_Ep60_Weightv3_GENDER ./model/mask/ResNet50_Ep60_Weightv3_MASK ./model/age/ResNet_Ep120_patience15_SplitProf_Downsample_CustAugv1_WeightedCEnSamplev1_SGD_AGE ./model/gender/ResNet_Ep120_patience15_SplitProf_Downsample_CustAugv1_WeightedCEnSamplev1_SGD_GENDER ./model/mask/ResNet_Ep120_patience15_SplitProf_Downsample_CustAugv1_WeightedCEnSamplev1_SGD_MASK \\\n",
    "./model/age/ResNet18_Ep60_Weightv3_AGE ./model/gender/ResNet18_Ep60_Weightv3_GENDER ./model/mask/ResNet18_Ep60_Weightv3_MASK ./model/age/ResNet50_Ep60_Weightv0_AGE ./model/gender/ResNet50_Ep60_Weightv0_GENDER2 ./model/mask/ResNet50_Ep60_Weightv0_MASK2 ./model/age/ResNet50_Ep60_Weightv3_AGE ./model/gender/ResNet50_Ep60_Weightv3_GENDER ./model/mask/ResNet50_Ep60_Weightv3_MASK\"\n",
    "\n",
    "configs_label = parse_config(model_dirs)\n",
    "for _, config in configs_label.items():\n",
    "    set_models(config)\n",
    "    \n",
    "assert all([configs_label['age'], configs_label['gender'], configs_label['mask']]) # must have em all\n",
    "age_soft, age_hard = inference_model(configs_label['age'], loader)\n",
    "gen_soft, gen_hard = inference_model(configs_label['gender'], loader)\n",
    "msk_soft, msk_hard = inference_model(configs_label['mask'], loader)\n",
    "    \n",
    "pred_soft = msk_soft*6 + gen_soft * 3 + age_soft\n",
    "pred_hard = msk_hard*6 + gen_hard * 3 + age_hard\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = ''\n",
    "output_filename = ''\n",
    "\n",
    "info['ans'] = pred_soft\n",
    "info.to_csv(os.path.join(output_dir, 'soft', output_filename), index=False)\n",
    "info['ans'] = pred_hard\n",
    "info.to_csv(os.path.join(output_dir, 'hard', output_filename), index=False)\n",
    "print(f'Inference Done!')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
